import json
import yaml
import os
import argparse

# --- Utility Functions ---

def read_service_definition(file_path):
    """
    Reads a service definition from a JSON or YAML file.
    In a real GenAI scenario, this input might come directly from a user prompt
    or a structured API call.
    """
    _, ext = os.path.splitext(file_path)
    if ext.lower() == '.json':
        with open(file_path, 'r') as f:
            return json.load(f)
    elif ext.lower() == '.yaml' or ext.lower() == '.yml':
        with open(file_path, 'r') as f:
            return yaml.safe_load(f)
    else:
        raise ValueError("Unsupported file format. Please use .json or .yaml")

def write_generated_iac(output_dir, file_name, content):
    """
    Writes the generated IaC content to a specified file within the output directory.
    """
    os.makedirs(output_dir, exist_ok=True)
    file_path = os.path.join(output_dir, file_name)
    with open(file_path, 'w') as f:
        f.write(content)
    print(f"Generated IaC written to: {file_path}")

# --- GenAI Simulation Logic (Templates for Demonstration) ---

# In a real GenAI system, these functions would not just use static templates,
# but would leverage an LLM's ability to dynamically compose and reason about
# cloud resources based on the input 'service_config'.
# The LLM would be prompted with the service_config and asked to output valid
# Terraform HCL or CloudFormation YAML.

def generate_terraform_hcl(service_config):
    """
    Simulates GenAI generating Terraform HCL for an AWS Fargate service with RDS PostgreSQL.
    This is a simplified template. A real GenAI would dynamically add more details.
    """
    service_name = service_config.get('service_name', 'default-service')
    port = service_config.get('port', 8080)
    db_config = service_config.get('database', {})
    db_type = db_config.get('type')
    db_version = db_config.get('version', '13.7')
    db_instance_size = db_config.get('instance_size', 'db.t3.micro')
    db_storage_gb = db_config.get('storage_gb', 20)
    db_username = db_config.get('username', 'admin')
    db_password_secret_name = db_config.get('password_secret_name', 'db-password-secret')
    env = service_config.get('environment', 'dev')

    if db_type != 'postgresql':
        print(f"Warning: Expected PostgreSQL but got {db_type}. Generating PostgreSQL anyway for demo.")

    terraform_template = f"""
# This Terraform configuration was dynamically generated by the GenAI-IaC-Java-Deployer.
# It provisions infrastructure for the '{service_name}' Java microservice.

provider "aws" {{
  region = "us-east-1" # Can be made dynamic
}}

# --- Networking (VPC, Subnets, Security Groups) ---
resource "aws_vpc" "app_vpc" {{
  cidr_block = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  tags = {{
    Name = "{service_name}-{env}-vpc"
    GenAI_Generated = "true"
  }}
}}

resource "aws_subnet" "public_subnet_a" {{
  vpc_id                  = aws_vpc.app_vpc.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "us-east-1a"
  map_public_ip_on_launch = true
  tags = {{
    Name = "{service_name}-{env}-public-a"
  }}
}}

resource "aws_subnet" "public_subnet_b" {{
  vpc_id                  = aws_vpc.app_vpc.id
  cidr_block              = "10.0.2.0/24"
  availability_zone       = "us-east-1b"
  map_public_ip_on_launch = true
  tags = {{
    Name = "{service_name}-{env}-public-b"
  }}
}}

resource "aws_internet_gateway" "gw" {{
  vpc_id = aws_vpc.app_vpc.id
  tags = {{
    Name = "{service_name}-{env}-igw"
  }}
}}

resource "aws_route_table" "public_rt" {{
  vpc_id = aws_vpc.app_vpc.id
  route {{
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.gw.id
  }}
  tags = {{
    Name = "{service_name}-{env}-public-rt"
  }}
}}

resource "aws_route_table_association" "public_a_assoc" {{
  subnet_id      = aws_subnet.public_subnet_a.id
  route_table_id = aws_route_table.public_rt.id
}}

resource "aws_route_table_association" "public_b_assoc" {{
  subnet_id      = aws_subnet.public_subnet_b.id
  route_table_id = aws_route_table.public_rt.id
}}

resource "aws_security_group" "app_sg" {{
  name_prefix = "{service_name}-app-sg-"
  vpc_id      = aws_vpc.app_vpc.id

  ingress {{
    from_port   = {port}
    to_port     = {port}
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"] # For demo, restrict in production
  }}
  ingress {{
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"] # For ALB health check
  }}
  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }}
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_security_group" "db_sg" {{
  name_prefix = "{service_name}-db-sg-"
  vpc_id      = aws_vpc.app_vpc.id

  ingress {{
    from_port   = 5432 # PostgreSQL default port
    to_port     = 5432
    protocol    = "tcp"
    security_groups = [aws_security_group.app_sg.id] # Allow connections from application SG
  }}
  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }}
  tags = {{
    GenAI_Generated = "true"
  }}
}}


# --- RDS PostgreSQL Database ---
resource "aws_db_subnet_group" "db_subnet_group" {{
  name        = "{service_name}-{env}-db-subnet-group"
  subnet_ids  = [aws_subnet.public_subnet_a.id, aws_subnet.public_subnet_b.id] # Using public for demo
  description = "Subnet group for {service_name} RDS"
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_db_instance" "rds_postgresql" {{
  allocated_storage    = {db_storage_gb}
  db_name              = "{service_name.replace('-', '_').lower()}_db"
  engine               = "postgres"
  engine_version       = "{db_version}"
  instance_class       = "{db_instance_size}"
  identifier           = "{service_name}-{env}-db"
  username             = "{db_username}"
  password             = data.aws_secretsmanager_secret_version.db_password.secret_string # Retrieved from Secrets Manager
  parameter_group_name = "default.postgres{db_version.split('.')[0]}"
  skip_final_snapshot  = true # For demo purposes
  vpc_security_group_ids = [aws_security_group.db_sg.id]
  db_subnet_group_name   = aws_db_subnet_group.db_subnet_group.name
  publicly_accessible = true # For demo purposes
  tags = {{
    Name = "{service_name}-{env}-rds"
    GenAI_Generated = "true"
  }}
}}

# Data source for retrieving DB password from AWS Secrets Manager
data "aws_secretsmanager_secret_version" "db_password" {{
  secret_id = "{db_password_secret_name}"
}}


# --- ECS Fargate Cluster and Service ---
resource "aws_ecs_cluster" "app_cluster" {{
  name = "{service_name}-{env}-cluster"
  tags = {{
    Name = "{service_name}-{env}-ecs-cluster"
    GenAI_Generated = "true"
  }}
}}

resource "aws_cloudwatch_log_group" "app_log_group" {{
  name = "/ecs/java-microservices/{service_name}"
  retention_in_days = 7 # Adjust as needed
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_iam_role" "ecs_task_execution_role" {{
  name = "{service_name}-ecs-task-execution-role"
  assume_role_policy = jsonencode({{
    Version = "2012-10-17"
    Statement = [
      {{
        Action    = "sts:AssumeRole"
        Effect    = "Allow"
        Principal = {{
          Service = "ecs-tasks.amazonaws.com"
        }}
      }},
    ]
  }})
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_iam_role_policy_attachment" "ecs_task_execution_role_policy" {{
  role       = aws_iam_role.ecs_task_execution_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
}}

resource "aws_iam_role_policy_attachment" "ecs_secretsmanager_access" {{
  role       = aws_iam_role.ecs_task_execution_role.name
  policy_arn = "arn:aws:iam::aws:policy/SecretsManagerReadWrite" # For demo, fine-tune in prod
}}


resource "aws_ecs_task_definition" "app_task" {{
  family                   = "{service_name}-task"
  cpu                      = "256"
  memory                   = "512"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  execution_role_arn       = aws_iam_role.ecs_task_execution_role.arn
  container_definitions    = jsonencode([
    {{
      name      = "{service_name}-container",
      image     = "public.ecr.aws/docker/library/openjdk:17-jdk-slim", # Placeholder Java image
      essential = true,
      portMappings = [
        {{
          containerPort = {port},
          hostPort      = {port},
          protocol      = "tcp"
        }}
      ],
      environment = [ # Example environment variables
        {{ name = "SPRING_DATASOURCE_URL", value = "jdbc:postgresql://${aws_db_instance.rds_postgresql.address}:${aws_db_instance.rds_postgresql.port}/${aws_db_instance.rds_postgresql.db_name}" }},
        {{ name = "SPRING_DATASOURCE_USERNAME", value = "{db_username}" }}
      ],
      secrets = [ # Inject DB password from Secrets Manager
        {{
          name = "SPRING_DATASOURCE_PASSWORD",
          valueFrom = "${data.aws_secretsmanager_secret_version.db_password.arn}"
        }}
      ],
      logConfiguration = {{
        logDriver = "awslogs",
        options = {{
          "awslogs-group"         = aws_cloudwatch_log_group.app_log_group.name,
          "awslogs-region"        = "us-east-1",
          "awslogs-stream-prefix" = "ecs"
        }}
      }}
    }}
  ])
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_ecs_service" "app_service" {{
  name            = "{service_name}-{env}-service"
  cluster         = aws_ecs_cluster.app_cluster.id
  task_definition = aws_ecs_task_definition.app_task.arn
  desired_count   = 1 # Start with 1, configure autoscaling for production
  launch_type     = "FARGATE"

  network_configuration {{
    subnets          = [aws_subnet.public_subnet_a.id, aws_subnet.public_subnet_b.id]
    security_groups  = [aws_security_group.app_sg.id]
    assign_public_ip = true
  }}

  load_balancer {{
    target_group_arn = aws_lb_target_group.app_tg.arn
    container_name   = "{service_name}-container"
    container_port   = {port}
  }}
  tags = {{
    GenAI_Generated = "true"
  }}
}}

# --- Application Load Balancer (ALB) ---
resource "aws_lb" "app_lb" {{
  name               = "{service_name}-{env}-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.app_sg.id] # Re-use app SG
  subnets            = [aws_subnet.public_subnet_a.id, aws_subnet.public_subnet_b.id]
  tags = {{
    Name = "{service_name}-{env}-alb"
    GenAI_Generated = "true"
  }}
}}

resource "aws_lb_target_group" "app_tg" {{
  name     = "{service_name}-{env}-tg"
  port     = {port}
  protocol = "HTTP"
  vpc_id   = aws_vpc.app_vpc.id

  health_check {{
    path                = "/actuator/health" # Assuming Spring Boot Actuator
    protocol            = "HTTP"
    matcher             = "200"
    interval            = 30
    timeout             = 5
    healthy_threshold   = 2
    unhealthy_threshold = 2
  }}
  tags = {{
    GenAI_Generated = "true"
  }}
}}

resource "aws_lb_listener" "http_listener" {{
  load_balancer_arn = aws_lb.app_lb.arn
  port              = 80
  protocol          = "HTTP"

  default_action {{
    type             = "forward"
    target_group_arn = aws_lb_target_group.app_tg.arn
  }}
  tags = {{
    GenAI_Generated = "true"
  }}
}}

# --- Outputs ---
output "alb_dns_name" {{
  description = "The DNS name of the Application Load Balancer"
  value       = aws_lb.app_lb.dns_name
}}

output "rds_endpoint" {{
  description = "The endpoint of the RDS PostgreSQL instance"
  value       = aws_db_instance.rds_postgresql.address
}}

"""
    return terraform_template

def generate_cloudformation_yaml(service_config):
    """
    Simulates GenAI generating CloudFormation YAML for an AWS Lambda service with DynamoDB and SQS.
    This is a simplified template. A real GenAI would dynamically add more details.
    """
    service_name = service_config.get('service_name', 'DefaultService')
    lambda_memory = service_config.get('memory_mb', 512)
    lambda_timeout = service_config.get('timeout_seconds', 30)
    db_config = service_config.get('database', {})
    db_type = db_config.get('type')
    db_table_name = db_config.get('table_name', 'default-table')
    db_partition_key = db_config.get('partition_key', 'id')
    db_sort_key = db_config.get('sort_key')
    db_read_capacity = db_config.get('read_capacity', 5)
    db_write_capacity = db_config.get('write_capacity', 5)
    msg_config = service_config.get('messaging', {})
    msg_type = msg_config.get('type')
    queue_name = msg_config.get('queue_name', 'default-queue')
    dlq_enabled = msg_config.get('dead_letter_queue', False)
    env = service_config.get('environment', 'dev')


    if db_type != 'dynamodb':
        print(f"Warning: Expected DynamoDB but got {db_type}. Generating DynamoDB anyway for demo.")
    if msg_type != 'sqs_queue':
        print(f"Warning: Expected SQS Queue but got {msg_type}. Generating SQS anyway for demo.")

    cloudformation_template = f"""
AWSTemplateFormatVersion: '2010-09-09'
Description: |
  CloudFormation template dynamically generated by GenAI-IaC-Java-Deployer
  for the '{service_name}' Java microservice (AWS Lambda, DynamoDB, SQS).

Parameters:
  ProjectName:
    Type: String
    Default: {service_name}
    Description: Name of the microservice.
  Environment:
    Type: String
    Default: {env}
    Description: Deployment environment (e.g., dev, staging, prod).

Resources:
  # --- AWS Lambda Function for Java Microservice ---
  {service_name}LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${{ProjectName}}-${{Environment}}-Function"
      Handler: com.example.{service_name.lower().replace('-', '')}.Handler::handleRequest # Placeholder, specific to Java handler
      Runtime: java17 # Specifies Java 17 runtime
      Code:
        S3Bucket: your-code-bucket-name # Replace with your S3 bucket for JAR file
        S3Key: {service_name.lower()}-{env}.jar # Replace with your JAR file key
      MemorySize: {lambda_memory}
      Timeout: {lambda_timeout}
      Role: !GetAtt LambdaExecutionRole.Arn
      Environment:
        Variables:
          TABLE_NAME: !Ref {db_table_name.replace('-', '')}DynamoDBTable
          QUEUE_URL: !Ref {queue_name.replace('-', '')}SQSQueue
          AWS_REGION: !Ref AWS::Region
      Tags:
        - Key: GenAI_Generated
          Value: "true"
        - Key: Service
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${{ProjectName}}-${{Environment}}-LambdaRole"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: LambdaAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - dynamodb:GetItem
                  - dynamodb:PutItem
                  - dynamodb:UpdateItem
                  - dynamodb:DeleteItem
                  - dynamodb:BatchGetItem
                  - dynamodb:BatchWriteItem
                  - dynamodb:Query
                  - dynamodb:Scan
                Resource: !GetAtt {db_table_name.replace('-', '')}DynamoDBTable.Arn
              - Effect: Allow
                Action:
                  - sqs:SendMessage
                  - sqs:ReceiveMessage
                  - sqs:DeleteMessage
                  - sqs:GetQueueAttributes
                  - sqs:GetQueueUrl
                Resource: !GetAtt {queue_name.replace('-', '')}SQSQueue.Arn
      Tags:
        - Key: GenAI_Generated
          Value: "true"

  # --- DynamoDB Table ---
  {db_table_name.replace('-', '')}DynamoDBTable:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: !Sub "${{ProjectName}}-${{Environment}}-{db_table_name}"
      AttributeDefinitions:
        - AttributeName: {db_partition_key}
          AttributeType: {"S" if db_partition_key == "id" else "N"} # Assuming 'id' is String for simplicity
{"        - AttributeName: " + db_sort_key + " # Requires type based on actual data" if db_sort_key else ""}
      KeySchema:
        - AttributeName: {db_partition_key}
          KeyType: HASH
{"        - AttributeName: " + db_sort_key + "\n          KeyType: RANGE" if db_sort_key else ""}
      BillingMode: PROVISIONED # Can be ON_DEMAND
      ProvisionedThroughput:
        ReadCapacityUnits: {db_read_capacity}
        WriteCapacityUnits: {db_write_capacity}
      Tags:
        - Key: GenAI_Generated
          Value: "true"
        - Key: Service
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

  # --- SQS Queue ---
  {queue_name.replace('-', '')}SQSQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub "${{ProjectName}}-${{Environment}}-{queue_name}"
      ReceiveMessageWaitTimeSeconds: 5
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt {queue_name.replace('-', '')}DLQ.Arn # If DLQ is enabled
        maxReceiveCount: 5
      Tags:
        - Key: GenAI_Generated
          Value: "true"
        - Key: Service
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

  {queue_name.replace('-', '')}DLQ:
    Type: AWS::SQS::Queue
    Condition: CreateDLQ # Only create if DLQ is enabled
    Properties:
      QueueName: !Sub "${{ProjectName}}-${{Environment}}-{queue_name}-dlq"
      Tags:
        - Key: GenAI_Generated
          Value: "true"
        - Key: Service
          Value: !Ref ProjectName
        - Key: Environment
          Value: !Ref Environment

Conditions:
  CreateDLQ: !Equals ["{dlq_enabled}", "True"] # Condition to enable DLQ creation

Outputs:
  LambdaFunctionName:
    Description: The name of the Lambda function
    Value: !Ref {service_name}LambdaFunction
  DynamoDBTableName:
    Description: The name of the DynamoDB table
    Value: !Ref {db_table_name.replace('-', '')}DynamoDBTable
  SQSQueueURL:
    Description: The URL of the SQS Queue
    Value: !Ref {queue_name.replace('-', '')}SQSQueue
"""
    return cloudformation_template


# --- Main Script Execution ---

def main():
    parser = argparse.ArgumentParser(
        description="Simulates GenAI-powered IaC generation for Java microservices."
    )
    parser.add_argument(
        '--input',
        required=True,
        help="Path to the JSON/YAML service definition file."
    )
    parser.add_argument(
        '--output-dir',
        default='generated_iac',
        help="Directory to save the generated IaC templates."
    )
    args = parser.parse_args()

    try:
        service_config = read_service_definition(args.input)
        compute_type = service_config.get('compute_type')
        service_name = service_config.get('service_name', 'unknown-service')

        if compute_type == 'aws_fargate':
            # Generate Terraform
            terraform_output = generate_terraform_hcl(service_config)
            output_path = os.path.join(args.output_dir, 'terraform')
            write_generated_iac(output_path, 'main.tf', terraform_output)
        elif compute_type == 'aws_lambda':
            # Generate CloudFormation
            cloudformation_output = generate_cloudformation_yaml(service_config)
            output_path = os.path.join(args.output_dir, 'cloudformation')
            write_generated_iac(output_path, 'template.yaml', cloudformation_output)
        else:
            print(f"Error: Unsupported compute_type '{compute_type}' in service definition.")
            print("Supported types are 'aws_fargate' (for Terraform) and 'aws_lambda' (for CloudFormation).")

    except Exception as e:
        print(f"An error occurred: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()